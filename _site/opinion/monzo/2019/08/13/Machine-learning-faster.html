<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Machine learning, faster | Neal Lathia</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Machine learning, faster" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work." />
<meta property="og:description" content="I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work." />
<link rel="canonical" href="http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html" />
<meta property="og:url" content="http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html" />
<meta property="og:site_name" content="Neal Lathia" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-13T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work.","headline":"Machine learning, faster","dateModified":"2019-08-13T00:00:00-05:00","datePublished":"2019-08-13T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html"},"url":"http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Neal Lathia" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Machine learning, faster | Neal Lathia</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Machine learning, faster" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work." />
<meta property="og:description" content="I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work." />
<link rel="canonical" href="http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html" />
<meta property="og:url" content="http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html" />
<meta property="og:site_name" content="Neal Lathia" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-13T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"I recently gave a couple of conference presentations about how we are thinking about speed when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we‚Äôre doing in the Monzo machine learning team to speed up our own work.","headline":"Machine learning, faster","dateModified":"2019-08-13T00:00:00-05:00","datePublished":"2019-08-13T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html"},"url":"http://0.0.0.0:4000/opinion/monzo/2019/08/13/Machine-learning-faster.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Neal Lathia" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Neal Lathia</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/research/">Research</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Machine learning, faster</h1><p class="page-description">I recently gave a couple of conference presentations about how we are thinking about _speed_ when developing machine learning systems at Monzo. This post covers some of the background to the points I was making in my talks, as well as what we&#39;re doing in the Monzo machine learning team to speed up our own work.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-08-13T00:00:00-05:00" itemprop="datePublished">
        Aug 13, 2019
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#opinion">opinion</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#monzo">monzo</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Speed is not a word that is regularly associated with machine learning teams. When we talk and write about accomplishments in machine learning, there is often a focus on the problem, the algorithmic approach, and the results - but no mention of the time that it took to get there.</p>

<h3 id="does-speed-matter-in-machine-learning">Does speed matter in machine learning?</h3>
<p>I remember once speaking with a machine learning researcher who worked at a large company. He told me that a product team had approached him with a very exciting idea that had to do with text summarisation. He started looking into the problem and made some very significant contributions over the course of 12 months - going so far as publishing papers in top-tier conferences about the topic. I asked him if his ideas made it into the product in question. Unfortunately, the answer was no: by the time his research was completed, the product team had moved on from this problem, and weren‚Äôt interested in having the solution anymore üò≠.</p>

<p>I‚Äôve heard many variants of this story: they all capture a misaligned pace of work between product and machine learning teams. Ultimately, this leads to machine learning research never making it out of the lab. And yet, the best measure of <em>impact</em> for machine learning, if you work in a non-research institution, is whether you can use it to help your customers - and that means getting it out of the door.</p>

<p>Speed matters. This goes beyond thinking about minimum viable products (and the ML equivalent of ‚Äúuse a logistic regression before you use a neural network‚Äù); this is about the speed of the entire lifecycle for building machine learning systems.</p>

<p>I covered four angles to this topic, when I gave talks about it recently:</p>

<h3 id="-quickly-deploying-models-to-production">üö¢ Quickly deploying models to production</h3>
<p>Quickly deploying models to production is one of the biggest roadblocks for impactful machine learning. In many companies, this boils down to <em>who is trusted</em> to do this work; often, ‚ÄòScientists‚Äô design and train a model, and then hand it over to ‚ÄòEngineers‚Äô to put it into production. This implicitly develops a ‚Äúthrow it over the wall‚Äù mentality: people who train models do not have to think about how complex it would be to ship, and folks who ship models can throw a model back over the wall if it‚Äôs not behaving how it should. The most common complaint I‚Äôve had from <em>Scientists</em> is along the lines of ‚ÄúI trained this model months ago and I‚Äôm just sitting here waiting for it to be shipped,‚Äù and <em>Engineers</em> retort that they get no recognition for doing all of the hard work of enabling production inference to actually happen. A frustrating experience all around.</p>

<p>At Monzo, Machine Learning Scientists deploy their own models. We are enabling that by focusing on our tooling. The goal that we set ourselves is that if you can write a <code class="highlighter-rouge">predict()</code> function for a machine learning model, you should also be able to <strong>safely</strong> deploy a model to production. To enable this, we‚Äôve built a <code class="highlighter-rouge">cookiecutter</code> microservice template that Machine Learning Scientists use: it guides them through a small set of options (e.g., ‚Äúwhich ML library are you using?‚Äù) and then creates everything they need, minus small bits, like the <code class="highlighter-rouge">predict()</code> function itself. We can now build and deploy a service in a matter of hours - right after we finish training a model. A <em>Scientist</em> does not have to wait around for others to finish the work, and can take an idea all the way from validation to deployment.</p>

<h3 id="-quickly-validating-misbehaviours">üîç Quickly validating misbehaviours</h3>
<p>Last year, after a re-launch of our <a href="https://monzo.com/blog/2017/08/22/the-help-search-algorithm">help screen search system</a>, a very common question that we would get from product teams is ‚Äúwhen I search for <code class="highlighter-rouge">X</code>, why doesn‚Äôt article <code class="highlighter-rouge">Y</code> show up?‚Äù Trying to explain machine learning algorithms is hard enough - diagnosing minor misbehaviours felt even more challenging. Has something gone wrong with our data pipeline, our model, or how we are post-processing the results down stream?</p>

<p>This is a type of problem that could grind us to a halt: it‚Äôs not the sort of thing we could write unit (or integration) tests for, and neither is it something where the problem is immediately clear. To tackle this quickly, we started writing <strong>validation tests</strong>: these are a set of fairly simple inputs (e.g. ‚Äúmoving home‚Äù) that have obvious outputs (the <a href="https://monzo.com/help/account-and-profile/update-home-address">updating my home address</a> article), which we expect our <strong>production</strong> machine learning system to be able to return when making predictions. These run in production: they are integrated into how we update the embeddings that are stored in the system, and prevent updates from happening if expected predictions fail (also, we get notified on Slack ‚ö†Ô∏è ).</p>

<p>Keeping track of the online performance of machine learning models is going beyond what we traditionally do when deploying software - writing validation tests is another small improvement that has helped us to keep on top of how these systems operate online.</p>

<h3 id="Ô∏è-quickly-repurposing-models-for-new-problems">‚ôªÔ∏è Quickly repurposing models for new problems</h3>
<p>Last year, Monzo went through a <a href="https://monzo.com/blog/2018/12/17/customer-support">challenging period</a> where non-urgent response times for customer support was in the order of days rather than hours. The entire company rallied behind this: engineers, designers, and lawyers all dropped what they were doing to respond to customers.</p>

<p>As part of enabling the entire company to answer customers, a set of topic-based queues were set up; the idea was that it is easier to train someone to answer one type of question rather than answer any kind of question. Our team was asked whether we could set up a way to detect what customers were talking about and automatically assign queries to queues accordingly. Typically, machine learning teams would start here with the usual questions (e.g., what data do we have?) and methods (e.g., training a classifier). However, this wasn‚Äôt a request to kick-start a project looking into text classification: this was a request to get something working and deployed, now.</p>

<p>One of the systems that we were already running at the time served recommendations to customer support agents - it looked at what customers said and returned recommendations for which of our many different saved responses may be appropriate to use. For example, if a customer says ‚ÄúI‚Äôve forgotten my PIN,‚Äù the system recommends a response that contains all of the details of how to recover it. This system is not explicitly <em>categorising</em> queries; it is mapping questions to recommended answers based on a similarity metric. However, the recommended answers could easily be mapped to categories!</p>

<p>We therefore quickly repurposed this system‚Äôs recommendations to solve for the queue classification problem: we wrapped the recommendations in <code class="highlighter-rouge">if</code> statements to redirect queries to queues based on what reply was recommended. This was deployed this in less than a day!</p>

<p>This lesson has stuck with us since then: combining rule engines <em>with</em> machine learning models can be used to quickly create, contextualise, or repurpose a decision system.</p>

<h3 id="-measuring-time-to-results-not-results">‚è∞ Measuring time-to-results, not results</h3>
<p>The systems mentioned above use an encoder architecture that was published in 2017 (based on the <em>Attention is all you need</em> <a href="https://arxiv.org/abs/1706.03762">paper</a>). While working on it, we felt that, overall, we were taking advantage of latest research when building our systems. Then, in 2018, deep pre-trained language models (like ELMo, ULMFit, BERT) appeared and started to take the top spot in a variety of research challenges - and many of them were open sourced. Every few months the state-of-the-art was changing. As a non-research team, that focuses on building systems, how could we keep up with this pace of research?</p>

<p>We decided to set ourselves a challenge: to explore how these techniques could work on as many different NLP problems as we could find, in a really short time (a couple of weeks). A typical approach here, which I have used before, is to embark on a new project for each idea: analyse the data, understand/refine the problem, train and evaluate models, and tweak until something starts looking promising. There was no way that, using this approach, we could evaluate tens of ideas in a fortnight. Instead, rather than trying to answer the question ‚Äúwhat is the best result I can get?,‚Äù we designed our work around ‚Äúhow long will it take to get a result?‚Äù</p>

<p>Switching our perspective led us towards taking a highly modular approach to our NLP work. We built a pipeline that creates supervised learning datasets from all of our chat data: we just point it to what we want to predict, and give it some additional arguments to tweak how we want the text to be processed. This tool is completely separate from anything that does any machine learning; for that, we built a number of Colab notebook <strong>templates</strong>, which take (as input) a dataset, and then run it through a specific algorithm (e.g., ULMFit). Our guiding principle was that anyone should be able to point a notebook at their dataset, and then run all the cells to get to a result.</p>

<p>Many of the experiments that we ran had poor results - and we have thrown them away. However, the pipelines that we used to get them have stayed and evolved, and are regularly used to generate the data that trains all of our models. This experience changed my perspective on <em>research</em> time: it is time well spent if we learn about new things and develop <em>tools</em> that allow us to apply it quickly (if we also get some good results, that‚Äôs a bonus!).</p>

<h3 id="Ô∏è-conclusions">‚¨áÔ∏è Conclusions</h3>
<p>There‚Äôs a famous quote that I‚Äôve often heard: ‚Äúto increase your success rate, double your failure rate‚Äù (it looks like <a href="https://en.wikiquote.org/wiki/Thomas_J._Watson">Thomas Watson</a> said this). This is as true in machine learning as it is anywhere else.</p>

<p>In the machine learning team at Monzo, we‚Äôve been thinking about this in terms of the <em>speed</em> of our work. This is not about cutting corners, being less rigorous, or skipping important steps of the work. Speed is about setting ourselves up to get results quickly, repurposing systems quickly, validate online behaviour quickly, and deploy to production quickly.</p>

<p>This post covers a few stories that shaped our views on speed - but this is always a work in progress. More posts to come! It is based on these two talks:</p>

<ul>
  <li>Speeding up Machine Learning Development April 2019, Xcede Data Science Networking Event. London.</li>
  <li>Using Deep Learning to Support Customer Operations March 2019, ReWork Deep Learning in Finance Summit. London.</li>
</ul>

<p>You can find the slides from my talk <a href="https://www.slideshare.net/neal.lathia/machine-learning-faster">here</a>; reach out <a href="https://twitter.com/neal_lathia">on twitter</a> if you have any thoughts!</p>

  </div><a class="u-url" href="/opinion/monzo/2019/08/13/Machine-learning-faster.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/nlathia" title="nlathia"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/neal_lathia" title="neal_lathia"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
