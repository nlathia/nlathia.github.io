<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to over engineer a sound classifier | Neal Lathia</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="How to over engineer a sound classifier" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Detecting a trivial sound in a quiet environment using deep learning." />
<meta property="og:description" content="Detecting a trivial sound in a quiet environment using deep learning." />
<link rel="canonical" href="http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html" />
<meta property="og:url" content="http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html" />
<meta property="og:site_name" content="Neal Lathia" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-02T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Detecting a trivial sound in a quiet environment using deep learning.","headline":"How to over engineer a sound classifier","dateModified":"2020-04-02T00:00:00-05:00","datePublished":"2020-04-02T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html"},"url":"http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Neal Lathia" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to over engineer a sound classifier | Neal Lathia</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="How to over engineer a sound classifier" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Detecting a trivial sound in a quiet environment using deep learning." />
<meta property="og:description" content="Detecting a trivial sound in a quiet environment using deep learning." />
<link rel="canonical" href="http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html" />
<meta property="og:url" content="http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html" />
<meta property="og:site_name" content="Neal Lathia" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-02T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Detecting a trivial sound in a quiet environment using deep learning.","headline":"How to over engineer a sound classifier","dateModified":"2020-04-02T00:00:00-05:00","datePublished":"2020-04-02T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html"},"url":"http://0.0.0.0:4000/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Neal Lathia" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Neal Lathia</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/research/">Research</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to over engineer a sound classifier</h1><p class="page-description">Detecting a trivial sound in a quiet environment using deep learning.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-02T00:00:00-05:00" itemprop="datePublished">
        Apr 2, 2020
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#machine-learning">machine-learning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h3 id="-hack-day-idea">üè° Hack day idea</h3>

<p>I recently moved our washing machine out to the garage, which meant that I couldn‚Äôt hear it beep when it was finished. I would have some ‚Äúfalse positive‚Äù trips out there (through the drizzly British rain!) when timers went off, only to find that the thing was still going. How horrendous.</p>

<p>It had also been a while since I wrote some code just for the sake of building something and I had never done anything with software and sound (recording, cleaning, classification). So, solving this first world problem for myself became my small üí° idea for a  hack project I could work on as the world slowly started locking itself down.</p>

<p>This post is an overview of what I built. It does not cover the day that I spent dusting off the old laptop and generally waiting for all of the updates to download (goodbye, Python 2.7!). It also does not give appropriate credit to the infinite StackOverflow posts that I read along the way.</p>

<p>All of the code for this is on Github in my <a href="https://github.com/nlathia/sound-detection">sound-detection</a> repo.</p>

<h3 id="-collecting-training-data">üéß Collecting training data</h3>

<p>The first thing I needed was some data: I used the <a href="https://people.csail.mit.edu/hubert/pyaudio/docs/">PyAudio library</a> for this.</p>

<p>PyAudio is a library that allows you to record audio by reading from a stream, in a similar way that you would read from a file. There was a bit of faff with figuring out sampling and frame rates - I ended up using default values that I found on different examples.</p>

<p>I ended up with the function below that I used to record 3-second long samples of audio. The function returns as a list of arrays - in case you‚Äôre wondering, <a href="https://www.pythoncentral.io/the-difference-between-a-list-and-an-array/">here‚Äôs a post about the difference</a>.</p>

<p>Critically, I also added a counter that would tell me (approximately) what percentage of the sample was ‚Äúsilent.‚Äù All I did was check what the max value of each array was; if it was less than a totally arbitrary value of 300, I counted it as silent. I tested this by recording a few samples and shouting at my computer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">record_sample</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">seconds</span><span class="o">=</span><span class="n">NUM_SECONDS</span><span class="p">):</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">count_silent</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rate</span> <span class="o">/</span> <span class="n">NUM_FRAMES</span> <span class="o">*</span> <span class="n">NUM_SECONDS</span><span class="p">)):</span>
        <span class="n">sound_data</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="s">'h'</span><span class="p">,</span> <span class="n">stream</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">NUM_FRAMES</span><span class="p">,</span> <span class="n">exception_on_overflow</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">sound_data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">SOUND_THRESHOLD</span><span class="p">:</span>
            <span class="n">count_silent</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sound_data</span><span class="p">)</span>
    <span class="n">percent_silent</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">count_silent</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">))</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s">"‚ÑπÔ∏è  Finished recording {seconds} seconds: {(percent_silent * 100):.2f}</span><span class="si">% </span><span class="s">silent."</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">frames</span><span class="p">,</span> <span class="n">percent_silent</span>
</code></pre></div></div>

<p>I saved any 3-second sample that wasn‚Äôt silent as a wav file, using the <a href="https://docs.python.org/3/library/wave.html">wave library</a>. Somehow, I recall seeing some error when I tried to write this function using a <code class="highlighter-rouge">with</code> statement, so I ended up opening and closing the file directly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">save_sample</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">):</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="s">"data"</span><span class="p">,</span>
        <span class="s">"live"</span><span class="p">,</span>
        <span class="n">f</span><span class="s">"Sound-{str(datetime.now())}.wav"</span>
    <span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s">"‚§µÔ∏è  Storing audio to: {file_path}..."</span><span class="p">)</span>
    <span class="n">wf</span> <span class="o">=</span> <span class="n">wave</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s">"wb"</span><span class="p">)</span>
    <span class="n">wf</span><span class="o">.</span><span class="n">setnchannels</span><span class="p">(</span><span class="n">NUM_CHANNELS</span><span class="p">)</span>
    <span class="n">wf</span><span class="o">.</span><span class="n">setsampwidth</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="n">wf</span><span class="o">.</span><span class="n">setframerate</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="n">wf</span><span class="o">.</span><span class="n">writeframes</span><span class="p">(</span><span class="n">b</span><span class="s">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">frames</span><span class="p">))</span>
    <span class="n">wf</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">file_path</span>
</code></pre></div></div>

<p>With this minimal setup, I did a couple rounds of laundry and ended up with a bunch of wav files! That was the end of day 1 of the hack project.</p>

<h3 id="-labels">üè∑ Labels</h3>

<p>For day 2, I started by having to label the data I had previously recorded. I did this manually, by listening to all of the recordings ‚Äì well, at least the first second of each one. Luckily, these washing machines don‚Äôt tend to beep or spin at random, so all I had to do was find when it started and stopped doing one of those things, and bulk move all of those files into a directory. At this point I was thinking of making a classifier that could tell me about different things that the machine was doing, so I created four groups: beeps, spinning, washing, and ‚Äúhuman‚Äù (which was usually me coming in and out of the room).</p>

<p>I‚Äôm used to regularly labelling text for our classifiers at work, but usually do things like listen to music while doing this. Stepping through and listening to audio files needs your eyes, ears, and hands - this was all encompassing. It is also a prime way to annoy other people in your household.</p>

<p>In summary: this was super boring, so I had a gin &amp; tonic while I was doing this. I ended up with 43 samples of <em>beeps</em>, 588 samples of the machine making noises as part of the wash cycle, 38 samples that were sounds from me, and 748 samples of the machine spinning. I would later come back to this and change it to two classes: beeping and not beeping - which is what I ended up using.</p>

<p>Once that data was sorted into different directories, I loaded up the file paths (and corresponding label/directory) into a Pandas data frame and then used <a href="https://scikit-learn.org/">scikit learn</a> for what it is best known for: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train test split</a>.</p>

<h3 id="-1d-convolution">ü§ñ 1D Convolution</h3>

<p>Okay, finally! Time for some machine learning. I fired up my browser to figure out how to even begin on this.</p>

<p>This is the bit of the hack that is intentionally over-engineered. I am very aware that all I really wanted to do was detect a high-pitched sound among mostly background noise, and so could have gone down the audio analysis route. But that‚Äôs not fun, so I didn‚Äôt do that.</p>

<p>At work, we primarily use PyTorch, and so that was my first port of call. I found <a href="https://pytorch.org/tutorials/beginner/audio_classifier_tutorial.html">this tutorial</a> which points to a paper called ‚ÄúVery Deep Convolutional Neural Networks for Raw Waveforms‚Äù (<a href="https://arxiv.org/pdf/1610.00087.pdf">here‚Äôs the PDF</a>). I skimmed the paper - it looks like it‚Äôs based on some dataset of urban sounds called <a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound8k</a>, which has 10 classes of sounds like horns, children playing, and dogs barking. The tutorial also links to <a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/audio_classifier_tutorial.ipynb">this Colab notebook</a>.</p>

<p>I first tried swapping my dataset into this notebook, but soon hit all sorts of errors. I think this boils down the fact that the tutorial was written for PyTorch 1.1.0, and I was running 1.4.0. Everything was broken.</p>

<p>I ended up going back to first principles. By that, I mean that it had been so long since I had worked at this level of detail in PyTorch that my first few attempts didn‚Äôt work at all, and I had to go and re-learn about 1-D convolutional layers. Here‚Äôs a <a href="https://www.youtube.com/watch?v=yd_j_zdLDWs">really good YouTube video</a> that helped me.</p>

<p>In the end, I made a neural net with a dimensionality reduction step (1-D convolution, batch norm, and max pool), and then a classifier (linear and softmax):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BeepNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BeepNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span>
              <span class="n">in_channels</span><span class="o">=</span><span class="n">NUM_CHANNELS</span><span class="p">,</span>
              <span class="n">out_channels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
              <span class="n">kernel_size</span><span class="o">=</span><span class="n">KERNEL_SIZE</span><span class="p">,</span>
              <span class="n">stride</span><span class="o">=</span><span class="n">STRIDE</span>
          <span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">NUM_CHANNELS</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">298</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">NUM_LABELS</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>Once this seemed to be working, I looked into using a GPU to train the model. I spent a while moving the data into Google Drive and reading about how I could <a href="https://stackoverflow.com/questions/48376580/google-colab-how-to-read-data-from-my-google-drive">load it all into a Colab notebook</a>. In the end, this was another unnecessary rabbit hole and I trained the whole thing in minutes on my laptop.</p>

<p>I trained the model for a few epochs and it converged pretty fast. I then looked at the examples of what it was doing, and the results seemed legit. I hear you asking - what did you do about overfitting? The answer is that I did absolutely nothing. A model that was overfit on these beeps (that all sound exactly the same) was fine.</p>

<p>You can see the notebook that I used <a href="https://github.com/nlathia/sound-detection/blob/master/model/Audio_Classifier.ipynb">here</a>.</p>

<h3 id="-deploying-to-production">‚è≠ Deploying to production</h3>

<p>The final stage was to make something that could use this model to detect the beeps, and somehow let me know.</p>

<p>At this stage, I had two different components: a PyAudio thing that would record samples and save them to a wav file, and a PyTorch model that would use torchaudio to load data from a file and give it to the model. Instead of figuring out a way for the PyAudio data to go directly to the model, I decided to keep what I already had and use the disk as an intermediary.</p>

<p>Here‚Äôs how I made this unnecessarily complicated: I decided that it would be unacceptably slow if all of this happened in a single process. So I turned back to an old friend, the <a href="https://docs.python.org/3/library/multiprocessing.html">multiprocessing</a> library - and found out how multiprocessing has a neat bug where <a href="https://bugs.python.org/issue35219">Python crashes on macOS</a>; setting some weird flag <code class="highlighter-rouge">export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES</code> before running it fixed this ü§∑‚Äç‚ôÇÔ∏è.</p>

<p>The main process in my pipeline records a sample of audio and (if it is not silent) saves it to a file; it then pops the path to the file onto a queue. On the other side, a classifier process reads from that queue and loads up and classifies any file that is popped onto it.</p>

<p>What does it do if it detects a beep? I hunted around for different options here. One of the first options I thought of was to <a href="https://realpython.com/python-send-email/">send myself an email</a>; the problem is that I‚Äôve turned off gmail notifications (and my life has been much better since). I then went down a rabbit hole of options - Signal, WhatsApp, SMS gateways, paid services, and all of that.</p>

<p>I settled on using Telegram, because I stumbled onto a <a href="https://medium.com/@ManHay_Hong/how-to-create-a-telegram-bot-and-send-messages-with-python-4cf314d9fa3e">Medium post</a> about setting up a bot and sending it a message with Python, and it looked do-able. But, what if the model <em>was</em> wrong? How could I avoid that short walk out to check? I decided that the pipeline should also send me the actual audio that it thought was a beep. Sending a snippet of audio via telegram was not something that looked super straightforward, until I ran into the <a href="https://github.com/python-telegram-bot/python-telegram-bot">Python Telegram Bot</a> library. The main problem I ran into was that this library would only send sound files that were formatted as mp3s. Instead of re-writing everything to always use mp3s, I found an mp3 encoder called <a href="https://formulae.brew.sh/formula/lame">lame</a> that could be installed via brew. I found that before finding any Python library that I could use directly, so I just called this function from Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">convert_to_mp3</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="n">path_fields</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="n">path_fields</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">".wav"</span><span class="p">,</span> <span class="s">".mp3"</span><span class="p">)</span>
    <span class="n">result_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_fields</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s">"üéß  Converting: {file_path} -&gt; {result_file}"</span><span class="p">)</span>
    <span class="n">command</span> <span class="o">=</span> <span class="n">f</span><span class="s">"lame --preset standard </span><span class="se">\"</span><span class="s">{file_path}</span><span class="se">\"</span><span class="s"> </span><span class="se">\"</span><span class="s">{result_file}</span><span class="se">\"</span><span class="s">"</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">command</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s">"üéß  Converted to mp3 with result={result}"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result_file</span>
</code></pre></div></div>

<h3 id="-thats-it-or-was-it">üéâ That‚Äôs it! ‚Ä¶Or was it?</h3>

<p>All of this means that I now take my super old laptop and fire up the pipeline after I‚Äôve started the machine. I then go and hang out, anxiously waiting for a message. Here‚Äôs how <a href="https://twitter.com/neal_lathia/status/1231322746593988611">I tweeted</a> when it started working!</p>

<p><img src="https://nlathia.github.io/blog/images/beep-net.jpg" alt="" title="BeepNet in action" /></p>

<p>The first time it worked, I was overloaded with messages. I had forgotten to add a way for it to <em>not</em> send me a message every time it detected a beep (which was happening in multiple 3-second interval successions), so I had to add in a way for it to be rate-limited to one message every X minutes.</p>

<p>There were also a couple of times that it didn‚Äôt seem to work: the classifier process would die, the laptop‚Äôs wifi would have briefly gone down, or other such oddities. So I added in a bunch of logging, a time out (it would message me if it hadn‚Äôt detected a beep in more than X minutes), and I added in the <a href="https://github.com/jd/tenacity">tenacity</a> library‚Äôs annotations so that it would retry message sending.</p>

<h3 id="-whats-next">üíª What‚Äôs next?</h3>

<p>All of the code for this is on Github in my <a href="https://github.com/nlathia/sound-detection">sound-detection</a> repo. Feel free to use it, find bugs, and tell me what‚Äôs wrong with it.</p>

<p>The silliest thing about all of this is that I now have to fire up my old laptop when I want it to monitor a laundry cycle. Some day in the future I‚Äôll think about spending some time getting this to work on a Raspberry Pi or some other device that I can leave out there.</p>

  </div><a class="u-url" href="/machine-learning/2020/04/02/How-to-overengineer-a-sound-classifier.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/nlathia" title="nlathia"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/neal_lathia" title="neal_lathia"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
