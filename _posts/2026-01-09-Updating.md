---
layout: post
title: "Updating & defending assumptions"
description: AI's progress slope
categories: [ai]
---

Here's one fun challenge to kick off 2026: list out the assumptions that you have about AI. They might be about what AI is good at, what's difficult about it, where it falters, what are its risks, which AI systems you think work well & what ways you think it's best for teams to adopt it and build with it. 

Are all of those assumptions still true? More importantly, should those assumptions be true for ever, or is there a threshold of capability that negates them? If so, how will you know when to change your mind?

This is everyone's challenge this year. You might be executing on a multi-year AI strategy that is grounded in last year's assumptions. You might be building systems based on risks that are no longer there (& not tackling new risks that are there now). This is particularly important for anyone building products: are the problems they address based on assumptions that will be true forever?

A mini example of that at play: when we first adopted AI coding tools, we were worried about them not being good enough for production. This was certainly one angle that I've seen taken for a lot of AI software products ("it's not good enough for production by itself, we make it so"). Fast forward many months and Staff Engineers are reviewing PRs with comments like "I couldn't have done it better myself." Time to update!

