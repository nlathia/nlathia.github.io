---
layout: post
title: "Recommender Systems @ SIGIR 2009"
description: Originally published on mobblog.cs.ucl.ac.uk
categories: [research]
---

There were two sessions on recommender systems at this year&#8217;s <a href="http://sigir2009.org/">ACM SIGIR</a> (held in Boston). Overall, it was a good conference- organised well, run smoothly. It became very quickly apparent to me (a first-timer to SIGIR) that this is a tight community of researchers; there were many hugs at the opening drinks. Here is a quick summary of the recommender system papers and a couple other noteworthy papers/events.</p>
<p><span id="more-887"></span><strong>On Social Networks and Collaborative Recommendation</strong>. A group from Glasgow explored the idea of random walks on the user-user, user-tag, and user-track graphs for personalising recommendations in social web contexts, like last.fm. The authors posted their dataset <a href="http://www.dcs.gla.ac.uk/~jj/data/lastfm_dataset.htm">online</a> (but- at time of writing, this link is broken). An interesting discussion broke out after the presentation, regarding <em>suitable graph subsampling when crawling online datasets</em>- the authors had removed users who had no social links, and all tracks that had been listened to by less than 8 users (why 8? I don&#8217;t know), in order to avoid the &#8220;sparsity problem,&#8221; which caused some stir in the audience.</p>
<p><strong>Learning to Recommend with Social Trust Ensemble</strong>. Researchers from Hong Kong university showed how to merge trust-values (such as those found in the <a href="http://www.trustlet.org/wiki/Extended_Epinions_dataset">Epinions dataset</a>) with state-of-the-art collaborative filtering algorithms that are based on matrix factorisation. An interesting paper, since most <a href="http://mobblog.cs.ucl.ac.uk/2008/02/28/filtering-by-trust/">trust-based approaches</a> rely on nearest-neighbour algorithms in order to maintain the transparency that seems required in this context. The authors said they may perform a user study to explore this latter problem, which I think would be very interesting.</p>
<p><strong>Fast Nonparametric Matrix Factorization for Large-Scale Collaborative Filtering</strong>. An ensemble of NEC Labs and Carnegie Mellon researchers presented a method for performing fast collaborative filtering- as the title suggests, their methods are nonparametric. They present both accuracy and run-time results; impressively, they ran a number of algorithms, and offered source code to anyone who would get in touch. By far the most math-y paper of the session, but well done guys!</p>
<p><strong>The Wisdom of the Few.</strong> This is a paper that I co-authored with <a href="http://technocalifornia.blogspot.com/2009/05/wisdom-of-few.html">Xavier Amatriain</a>, who presented at SIGIR (I presented the follow up work at an <a href="http://mobblog.cs.ucl.ac.uk/2009/07/12/ijcai-09-workshop-on-intelligent-techniques-for-web-personalization-recommender-systems/">IJCAI workshop</a>), while I was an intern at Telefonica research. The basic idea is to use a small dataset of &#8216;experts&#8217; in order to predict the masses&#8217; preferences. While a small number of experts did not prove to be sufficient to out-predict other methods, an extensive user study showed opposing results: the users liked the expert recommendations more.</p>
<p><strong>Personalized Tag Recommendation Using Graph-Based Ranking on Multi-type Interrelated Objects</strong>. I find the problem of recommending tags interesting because users are being suggested <em>how to annotate content</em> (rather than the traditional recommender problem of suggesting <em>what content</em> to rate/annotate). I would like to see a study comparing the performance differences (in retrieval/recommendation) when using a dataset produced with tag recommendation and without- perhaps the tag recommendations denoises the data? The authors approach the tag-recommendation problem by formulating it as a retrieval problem, where the document and user are the query and the suggested tags are the result.</p>
<p>A related paper (external to the Recommenders session) is <strong>A Statistical Comparison of Tag and Query Logs</strong>, a paper that compares the way people tag to the way that they search- looking at word overlap and term distribution</p>
<p><strong>Leveraging Sources of Collective Wisdom on the Web for Discovering Technology Synergies</strong>. Unfortunately Ziegler was not here to present his work (who wrote <a href="http://www.informatik.uni-freiburg.de/~cziegler/papers/A4-Thesis.pdf">his PhD thesis</a> on decentralised recommender systems), and a Siemens representative replaced him. The paper dealt with an automated way of finding technological synergies between departments in a large R&amp;D organisation (like Siemens!)</p>
<p>Other than the above recommender-related papers, there were two UCL contributions (that appeared in the Retrieval Models session): &#8220;<strong>Risky Business: Modeling and Exploiting Uncertainty in Information Retrieval</strong>&#8221; and &#8220;<strong>Portfolio Theory of Information Retrieval</strong>.&#8221; I am planning on reading these soon; more details are available on <a href="http://web4.cs.ucl.ac.uk/staff/jun.wang/blog/">Jun Wang&#8217;s (excellent) blog</a>.</p>
<p>There was also an extensive <a href="http://sigir2009.org/Program/posters">poster session</a> (I was, however, busy attending to <a href="http://www.cs.ucl.ac.uk/staff/n.lathia/publications/sigir09.html">mine</a>), sessions on Web 2.0, interactive search, and multimedia (amongst others),  a keynote by <a href="http://sigir2009.org/Program/keynotes#barabasi">Barabasi</a>, a banquet at the JFK museum, a boat ride on the harbor, and a number of <a href="http://sigir2009.org/Program/workshops">workshops</a>. I&#8217;ll limit this post to the recommender system stuff. More details on the workshop to come.</p>

		
