---
layout: post
title: "Deep learning & medical diagnosis"
tags: [machine-learning, health]
excerpt_separator: <!--more-->
---

A growing list of areas where machine learning is being applied for diagnosis based on medical imaging.
<!--more-->

Over the last few months, there have been a number of announcements of research findings that claim that deep learning has been applied to, and often times immediately outperforms doctors in, a particular area of diagnosis.

I originally started this blog post to keep track of them — I’m going to publish it as a draft that I expect to update on a regular basis.

## What is deep learning in medical image diagnosis trying to do?
Before diving into the specific results, I’d like to highlight that the approaches (so far) below share the same common pattern. I’ve tried to summarize this into the following sentence:

> Diagnosis via machine learning works when the condition can be reduced to a classification task on physiological data, in areas where we currently rely on the clinician to be able to visually identify patterns that indicate the presence or type of the condition.

To break this down into details:
- **Classification**. The results are areas of medical diagnosis that can be reduced to a [classification problem](https://en.wikipedia.org/wiki/Statistical_classification): given some data, diagnosis can be reduced to the problem of mapping that data to one of N different outcomes. In some cases, N = 2: the task is just to identify whether the data (e.g., an x-ray) displays the condition or not. Note that there are other problems (e.g., image segmentation) that can be tackled with deep learning, but I haven’t yet seen them used in isolation for diagnosis (as opposed to, say, analysis only).
- **Physiological data**. The results below tend to be using medical imaging data or data from other kinds of sensors. The explosion of results in these areas is, in large part, ascribed to the creation of data sets (e.g., [these ones](http://www.radrounds.com/profiles/blogs/list-of-open-access-medical-imaging-datasets)) that are far larger than those that were previously available. A common approach to annotate a data set (e.g., label whether an x-ray contains a tumor) is to have a set of clinicians give their opinion and to collate the responses.
- **We rely on visually identifying patterns**. The alternative to an automated diagnosis system would be to have an expert clinician look at your data (perhaps discuss it with some fellow experts) to determine the outcome. This point captures why deep learning should be successful in this area: deep learning automates the entire process of extracting patterns and learning relationships in this kind of ‘unstructured’ data. There are many non-medical applications of deep learning (e.g., [face recognition](https://en.wikipedia.org/wiki/DeepFace)) that have similar requirements; because of this, the tech is quite mature. Indeed, even models trained on medical images are now being [open sourced](https://github.com/DLTK/models).

For great reviews of the area, check out the review papers and blog posts that I’ve added in the references section at the bottom of this post.

## Where should this approach not work?

The pattern above gives some insight into areas where this approach should not currently work. Like [this article mentions](https://lukeoakdenrayner.wordpress.com/2016/11/27/do-computers-already-outperform-doctors/), deep learning does not tell us how patients should be treated or how well they will fare when being treated. However, specifically related to the points above, there are domains that:
- Aren’t classification problems. If we don’t understand the disease well enough, we can’t create data to train any algorithm. For example, there are conditions that do not have a well-understood progression that can be enumerated into a set of stages. In these cases, it would be very challenging to build a reliable model to tell us what stage of progression a patient is at — because we don’t know what the stages should be.
- Lack (or have subjective) data. If there is little or no data, we cannot train models. Granted, this is starting to change — there are deep learning experiments that demonstrate [learning from extremely small data sets](https://medium.com/@radekosmulski/can-we-beat-the-state-of-the-art-from-2013-with-only-0-046-of-training-examples-yes-we-can-18be24b8615f). Where there is data, but it and/or patterns within it are subjective (e.g., the momentary experience of pain or stress), then I’d imagine that the approaches below would need to be re-imagined.
- Do not rely on medical devices. Similarly, domains where a diagnosis cannot be derived by attaching the patient to some kind of machine and collecting a single “sample” of data (e.g., requiring long-term tracking or [diagnosis by exclusion](https://en.wikipedia.org/wiki/Diagnosis_of_exclusion)). This could be because (a) we have not developed a means of detecting a disease — so, like above, more fundamental research is required, or (b) we have not developed viable products for long-term, non-invasive monitoring to collect the data that enables machine learning.

## List of Medical Conditions

My criteria for adding to this list: (a) a data set has been released, (b) research has been published,(c) a company or research group has written about work in progress, or (d) there are blog posts that describe tackling the problem. I’ve sorted the conditions alphabetically.

Have I missed something? You can [@ me on twitter](https://twitter.com/neal_lathia) and I’ll add it.

### Alzheimer’s

… “is a [chronic neurodegenerative](https://en.wikipedia.org/wiki/Alzheimer%27s_disease) disease that usually starts slowly and worsens over time.” Researchers in London have [published a paper](https://arxiv.org/abs/1502.02506) that reports using data from [the ADNI](http://www.adni-info.org/Scientists/ADNIData.html) to train a 3 layer neural network with a single convolutional layer that can predict whether an [MRI scan](https://en.wikipedia.org/wiki/Magnetic_resonance_imaging) is a healthy brain, a brain with mild cognitive impairment, and a brain with Alzheimer’s disease.

### Arrhythmia

… “is a [group of conditions](https://en.wikipedia.org/wiki/Heart_arrhythmia) in which the heartbeat is irregular.” Researchers at Stanford have [published a paper](https://arxiv.org/abs/1707.01836) that reports that a 34 layer convolutional neural network they developed “exceeds the performance of board certified cardiologists in detecting a wide range of heart arrhythmias from electrocardiograms recorded with a single-lead wearable monitor” ([project page](https://stanfordmlgroup.github.io/projects/ecg/), [blog post](https://blog.acolyer.org/2017/08/14/cardiologist-level-arrhythmia-detection-with-convolutional-neural-networks/)).


### Autism</h4>

<p name="c377" id="c377" class="graf graf--p graf-after--h4">… “is a <a href="https://en.wikipedia.org/wiki/Autism" data-href="https://en.wikipedia.org/wiki/Autism" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">neurodevelopmental disorder</a> characterized by impaired social interaction.” A team of researchers <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5336143/" data-href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5336143/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">published a paper</a>, which reports that “a deep learning algorithm primarily using surface area information from brain MRI at 6 and 12 months of age predicted the 24 month diagnosis of autism in children at high familial risk for autism”(via <a href="https://twitter.com/datarequena/status/938437786037825536" data-href="https://twitter.com/datarequena/status/938437786037825536" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@datarequena</a> on twitter).</p><h4 name="fb92" id="fb92" class="graf graf--h4 graf-after--p">Breast Cancer</h4><p name="d412" id="d412" class="graf graf--p graf-after--h4">… “is a cancer that <a href="https://en.wikipedia.org/wiki/Breast_cancer" data-href="https://en.wikipedia.org/wiki/Breast_cancer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">develops from breast tissue</a>.” <a href="https://deepmind.com/applied/deepmind-health/" data-href="https://deepmind.com/applied/deepmind-health/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">DeepMind Health</a> has published <a href="https://deepmind.com/blog/applying-machine-learning-mammography/" data-href="https://deepmind.com/blog/applying-machine-learning-mammography/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">a blog pos</a>t where they announced that they have teamed up with Cancer Research UK to analyse and apply machine learning on anonymised <a href="https://en.wikipedia.org/wiki/Mammography" data-href="https://en.wikipedia.org/wiki/Mammography" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">mammograms</a> from 7,500 women.</p><h4 name="6ac5" id="6ac5" class="graf graf--h4 graf-after--p">Dental Cavities</h4><p name="22b2" id="22b2" class="graf graf--p graf-after--h4">… “is a <a href="https://en.wikipedia.org/wiki/Tooth_decay" data-href="https://en.wikipedia.org/wiki/Tooth_decay" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">break down of teeth</a> due to acids made by bacteria.” Researchers at <a href="https://paralleldots.xyz/" data-href="https://paralleldots.xyz/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">ParallelDots</a> have <a href="https://arxiv.org/abs/1711.07312v2" data-href="https://arxiv.org/abs/1711.07312v2" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">published a paper</a> that reports that a 100+ layer convolutional network that performs pixel-level binary classification of teeth radiographs (has caries/does not have caries).</p><h4 name="77f0" id="77f0" class="graf graf--h4 graf-after--p">Diabetic Retinopathy</h4><p name="7623" id="7623" class="graf graf--p graf-after--h4">… “is a <a href="https://en.wikipedia.org/wiki/Diabetic_retinopathy" data-href="https://en.wikipedia.org/wiki/Diabetic_retinopathy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">medical condition</a> in which damage occurs to the retina due to diabetes.” Over two years ago, there was a <a href="https://www.kaggle.com/c/diabetic-retinopathy-detection" data-href="https://www.kaggle.com/c/diabetic-retinopathy-detection" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">kaggle competition</a> that sought to classify images of eyes into one of 5 classes (from <em class="markup--em markup--p-em">no diabetic retinopathy</em>, to <em class="markup--em markup--p-em">mild</em>, <em class="markup--em markup--p-em">moderate</em>, <em class="markup--em markup--p-em">severe</em>, and <em class="markup--em markup--p-em">proliferative</em>). The winning solution used a combination of <a href="https://github.com/facebookresearch/SparseConvNet" data-href="https://github.com/facebookresearch/SparseConvNet" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">sparse convolutional networks</a> and a random forest to make a prediction from a pair of images (left and right eye) to the outcome.</p><h4 name="6efb" id="6efb" class="graf graf--h4 graf-after--p">Gram Stains</h4><p name="a23a" id="a23a" class="graf graf--p graf-after--h4">… are a “<a href="https://en.wikipedia.org/wiki/Gram_stain" data-href="https://en.wikipedia.org/wiki/Gram_stain" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">method</a> of <a href="https://en.wikipedia.org/wiki/Staining" data-href="https://en.wikipedia.org/wiki/Staining" class="markup--anchor markup--p-anchor" title="Staining" rel="noopener" target="_blank">staining</a> used to distinguish and classify <a href="https://en.wikipedia.org/wiki/Bacteria" data-href="https://en.wikipedia.org/wiki/Bacteria" class="markup--anchor markup--p-anchor" title="Bacteria" rel="noopener" target="_blank">bacterial</a> species into two large groups.” It is a laboratory technique that is performed on bodily fluids (e.g., blood) when an infection is suspected. Researchers have <a href="http://jcm.asm.org/content/early/2017/11/24/JCM.01521-17" data-href="http://jcm.asm.org/content/early/2017/11/24/JCM.01521-17" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">published a paper</a> (cited in <a href="https://www.digitaltrends.com/cool-tech/microscope-blood-infections-ai/" data-href="https://www.digitaltrends.com/cool-tech/microscope-blood-infections-ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">this article</a>) that describes using a convolutional neural network to classify microscope images into <a href="https://en.wikipedia.org/wiki/Gram-positive_bacteria" data-href="https://en.wikipedia.org/wiki/Gram-positive_bacteria" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">gram-positive</a>, <a href="https://en.wikipedia.org/wiki/Gram-negative_bacteria" data-href="https://en.wikipedia.org/wiki/Gram-negative_bacteria" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">gram-negative</a>, and background (no cells). In the paper, they describe that they did not train a CNN from scratch; they fine-tuned <a href="https://arxiv.org/abs/1512.00567" data-href="https://arxiv.org/abs/1512.00567" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Inception v3</a> for this task.</p><h4 name="6213" id="6213" class="graf graf--h4 graf-after--p">Lung Cancer</h4><p name="95d0" id="95d0" class="graf graf--p graf-after--h4">… “is a <a href="https://en.wikipedia.org/wiki/Lung_cancer" data-href="https://en.wikipedia.org/wiki/Lung_cancer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">malignant tumor</a> characterized by uncontrolled cell growth in tissues of the lung.” This <a href="https://www.kaggle.com/c/data-science-bowl-2017#description" data-href="https://www.kaggle.com/c/data-science-bowl-2017#description" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">2017 kaggle competition</a> included a data set of <a href="https://en.wikipedia.org/wiki/CT_scan" data-href="https://en.wikipedia.org/wiki/CT_scan" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">CT scans</a>, and the goal was to predict the likelihood of lung cancer. There were some interesting challenges here, including the fact that the data is in 3-dimensions — the write-ups of <a href="http://blog.kaggle.com/2017/06/29/2017-data-science-bowl-predicting-lung-cancer-2nd-place-solution-write-up-daniel-hammack-and-julian-de-wit/" data-href="http://blog.kaggle.com/2017/06/29/2017-data-science-bowl-predicting-lung-cancer-2nd-place-solution-write-up-daniel-hammack-and-julian-de-wit/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">winning solutions</a> describe some interesting ways to tackle this. This <a href="https://medium.com/@alexandrecadrin/lung-cancer-bridging-the-gap-between-medical-imaging-and-data-science-a92b0bb08fda" data-href="https://medium.com/@alexandrecadrin/lung-cancer-bridging-the-gap-between-medical-imaging-and-data-science-a92b0bb08fda" class="markup--anchor markup--p-anchor" target="_blank">blog post outlines some of the limitations of this competition</a>, from a clinical perspective. Separately, it looks like <a href="https://www.enlitic.com/press-release-11162016.html" data-href="https://www.enlitic.com/press-release-11162016.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Enlitic is also working on</a> a lung cancer screening solution.</p><h4 name="744f" id="744f" class="graf graf--h4 graf-after--p">Onychomycosis</h4><p name="b8c4" id="b8c4" class="graf graf--p graf-after--h4">… “is a <a href="https://en.wikipedia.org/wiki/Onychomycosis" data-href="https://en.wikipedia.org/wiki/Onychomycosis" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">fungal infection of the nail</a>.” As <a href="https://twitter.com/DrLukeOR/status/954670235704901632" data-href="https://twitter.com/DrLukeOR/status/954670235704901632" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">this tweet</a> pointed out, researchers in Korea have <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191493#pone-0191493-t001" data-href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191493#pone-0191493-t001" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">published a paper</a> that reports using CNNs (VGG-19, ResNet-152) to both create a training dataset (e.g., extracting hand and foot images from a clinical photographs) as well as classify nails into one of six classes (as follows: (onychomycosis, nail dystrophy, onycholysis, melanonychia, normal, and others) to achieve “a diagnostic accuracy for onychomycosis using deep learning that was superior to that of most of the dermatologists who participated in this study.”</p><h4 name="ce49" id="ce49" class="graf graf--h4 graf-after--p">Pneumonia</h4><p name="0e1d" id="0e1d" class="graf graf--p graf-after--h4">… “is an <a href="https://en.wikipedia.org/wiki/Pneumonia" data-href="https://en.wikipedia.org/wiki/Pneumonia" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">inflammatory condition</a> of the lung affecting primarily the small air sacs known as alveoli.” Researchers at Stanford have <a href="https://arxiv.org/abs/1711.05225" data-href="https://arxiv.org/abs/1711.05225" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">published a paper</a> that reports that a 121 layer convolutional neural network they developed “can detect pneumonia from chest X-rays at a level exceeding practicing radiologists” (<a href="https://stanfordmlgroup.github.io/projects/chexnet/" data-href="https://stanfordmlgroup.github.io/projects/chexnet/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">project page</a>).</p><h4 name="2556" id="2556" class="graf graf--h4 graf-after--p">Skin Cancer</h4><p name="7826" id="7826" class="graf graf--p graf-after--h4">… “are due to the development of <a href="https://en.wikipedia.org/wiki/Skin_cancer" data-href="https://en.wikipedia.org/wiki/Skin_cancer" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">abnormal cells that have the ability to invade or spread to other parts of the body</a>.” Researchers at Stanford have published a paper that reports fine-tuning <a href="https://www.tensorflow.org/tutorials/image_recognition" data-href="https://www.tensorflow.org/tutorials/image_recognition" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Inception v3</a> to classify 757 disease classes, using a “dermatologist-labelled dataset of 129,450 clinical images, including 3,374 dermoscopy images.” The results are examined across different prediction tasks and accuracy rates seem comparable to the clinicians’ scores.</p><p name="f797" id="f797" class="graf graf--p graf-after--p">…I’m sure that this list will grow.</p><h3 name="17f0" id="17f0" class="graf graf--h3 graf-after--p">References &amp; Resources</h3><div name="1aad" id="1aad" class="graf graf--mixtapeEmbed graf-after--h3"><a href="https://arxiv.org/abs/1702.05747" data-href="https://arxiv.org/abs/1702.05747" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://arxiv.org/abs/1702.05747"><strong class="markup--strong markup--mixtapeEmbed-strong">[1702.05747] A Survey on Deep Learning in Medical Image Analysis</strong><br><em class="markup--em markup--mixtapeEmbed-em">Abstract: Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice…</em>arxiv.org</a><a href="https://arxiv.org/abs/1702.05747" class="js-mixtapeImage mixtapeImage mixtapeImage--empty u-ignoreBlock" data-media-id="ddd955bb7e10da187435113e9bac3a6b"></a></div><div name="4448" id="4448" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/the-mission/up-to-speed-on-deep-learning-in-medical-imaging-7ff1e91f6d71" data-href="https://medium.com/the-mission/up-to-speed-on-deep-learning-in-medical-imaging-7ff1e91f6d71" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/the-mission/up-to-speed-on-deep-learning-in-medical-imaging-7ff1e91f6d71"><strong class="markup--strong markup--mixtapeEmbed-strong">Up to Speed on Deep Learning in Medical Imaging</strong><br><em class="markup--em markup--mixtapeEmbed-em">Overview of current approaches, publicly available data sets, where the field is headed,and opportunities for the…</em>medium.com</a><a href="https://medium.com/the-mission/up-to-speed-on-deep-learning-in-medical-imaging-7ff1e91f6d71" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0cc3db8972653aedca8e9706b92d10b4" data-thumbnail-img-id="1*1tQi_sYvVEHuFHfB2JB_Bg.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*1tQi_sYvVEHuFHfB2JB_Bg.jpeg);"></a></div><div name="24c4" id="24c4" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447633/" data-href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447633/" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447633/"><strong class="markup--strong markup--mixtapeEmbed-strong">Deep Learning in Medical Imaging: General Overview</strong><br><em class="markup--em markup--mixtapeEmbed-em">Machine learning (ML) is defined as a set of methods that automatically detect patterns in data, and then utilize the…</em>www.ncbi.nlm.nih.gov</a><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447633/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="e729ddc0a272edb2513ed9708f10fab4" data-thumbnail-img-id="0*M4XdIXB8R9nzpIWD." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*M4XdIXB8R9nzpIWD.);"></a></div><div name="22db" id="22db" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="http://www.sciencedirect.com/science/article/pii/S1361841517301135" data-href="http://www.sciencedirect.com/science/article/pii/S1361841517301135" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://www.sciencedirect.com/science/article/pii/S1361841517301135"><strong class="markup--strong markup--mixtapeEmbed-strong">A survey on deep learning in medical image analysis - ScienceDirect</strong><br><em class="markup--em markup--mixtapeEmbed-em">Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for…</em>www.sciencedirect.com</a><a href="http://www.sciencedirect.com/science/article/pii/S1361841517301135" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="83f68ad48e5129e47490d6bb2aefdaae" data-thumbnail-img-id="0*USwT2WV17gBq2o_1." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*USwT2WV17gBq2o_1.);"></a></div><div name="63f3" id="63f3" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed graf--trailing"><a href="https://github.com/albarqouni/Deep-Learning-for-Medical-Applications" data-href="https://github.com/albarqouni/Deep-Learning-for-Medical-Applications" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/albarqouni/Deep-Learning-for-Medical-Applications"><strong class="markup--strong markup--mixtapeEmbed-strong">albarqouni/Deep-Learning-for-Medical-Applications</strong><br><em class="markup--em markup--mixtapeEmbed-em">Deep-Learning-for-Medical-Applications - Deep Learning Papers on Medical Image Analysis</em>github.com</a><a href="https://github.com/albarqouni/Deep-Learning-for-Medical-Applications" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="3007384f5d373f81f89a9dfe80d2b32b" data-thumbnail-img-id="0*EqFw9kq_u6AolYBb." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*EqFw9kq_u6AolYBb.);"></a></div></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@neal_lathia" class="p-author h-card">Neal Lathia</a> on <a href="https://medium.com/p/c04d35fc2830"><time class="dt-published" datetime="2017-12-04T11:51:53.600Z">December 4, 2017</time></a>.</p><p><a href="https://medium.com/@neal_lathia/deep-learning-medical-diagnosis-c04d35fc2830" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on August 11, 2019.</p></footer></article></body></html>